{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling of time in pyaerocom\n",
    "\n",
    "**NOTE**: the topics of this notebook are not necessarily required for using *pyaerocom*. It \n",
    "The [GriddedData](http://aerocom.met.no/pya/api.html#module-pya.griddeddata) class of *pyaerocom* was introduced in a previous tutorial.\n",
    "\n",
    "Here, we illustrate how *pyaerocom* handles time. In particular, how *pyaerocom* performs the conversion of CF conform numerical time stamps with a defined unit (i.e. basedate and calendar, see e.g. [here](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.6/build/cf-conventions.html#time-coordinate) for details) into datetime-like objects that can be interpreted by tools such as [Pandas](https://pandas.pydata.org/). \n",
    "\n",
    "The easiest way to work with time stamps in model data is, to simply work on the internal numerical indices, avoiding the necessity to convert them into actual datetime objects. However, sometimes (e.g. if we want to extract and analyse a time-series of global average Aerosol optical densities), we wish to use third party libraries such as Pandas, which require the timestamps to be datetime-like objects.\n",
    "\n",
    "This notebook illustrates how time is handled in the iris module, particularly in the [Cube](http://scitools.org.uk/iris/docs/v1.9.0/html/iris/iris/cube.html#iris.cube.Cube) class, which is the basic data representation object in the *pya* `GriddedData` class. In particular, it emphazises some peculiarities that can lead to complications and finally shows, how *pya* circumvents these issues. We shall see, that this does not only reduce the risk of conversion Errors, but even results in a quite significant performance boost when converting from numerical CF timestamps to `numpy.datetime64` time stamps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and some example data \n",
    "\n",
    "Get and load test data file using the new pya interface (the underlying datatype of `GriddedData` is `iris.cube.Cube`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaerocom as pya\n",
    "files = pya.io.testfiles.get()\n",
    "\n",
    "fpath_ecmwf = files['models']['ecmwf_osuite']\n",
    "fpath_aatsr = files['models']['aatsr_su_v4.3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonasg/anaconda3/lib/python3.6/site-packages/iris/fileformats/_pyke_rules/compiled_krb/fc_rules_cf_fc.py:1808: UserWarning: Ignoring netCDF variable 'od550aer' invalid units '~'\n",
      "  warnings.warn(msg)\n",
      "/home/jonasg/anaconda3/lib/python3.6/site-packages/iris/fileformats/_pyke_rules/compiled_krb/fc_rules_cf_fc.py:1808: UserWarning: Ignoring netCDF variable 'od550bc' invalid units '~'\n",
      "  warnings.warn(msg)\n",
      "/home/jonasg/anaconda3/lib/python3.6/site-packages/iris/fileformats/_pyke_rules/compiled_krb/fc_rules_cf_fc.py:1808: UserWarning: Ignoring netCDF variable 'od550so4' invalid units '~'\n",
      "  warnings.warn(msg)\n",
      "/home/jonasg/anaconda3/lib/python3.6/site-packages/iris/fileformats/_pyke_rules/compiled_krb/fc_rules_cf_fc.py:1808: UserWarning: Ignoring netCDF variable 'od550oa' invalid units '~'\n",
      "  warnings.warn(msg)\n",
      "/home/jonasg/anaconda3/lib/python3.6/site-packages/iris/fileformats/_pyke_rules/compiled_krb/fc_rules_cf_fc.py:1808: UserWarning: Ignoring netCDF variable 'od550dust' invalid units '~'\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "data_ecmwf = pya.GriddedData(fpath_ecmwf, var_name=\"od550aer\", name=\"ECMWF_OSUITE\")\n",
    "data_aatsr = pya.GriddedData(fpath_aatsr, var_name=\"od550aer\", name=\"AATSR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, if the longitudes are defined on a 0 -> 360 degree grid, they are automatically converted to -180 -> 180 (the case of the ECMWF data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digging into the time representation of the iris Cube datatype\n",
    "\n",
    "The `GriddedData` class is based on the `iris.Cube` object, which can be accessed via the `grid` attribute. In the following, some features of the `Cube` class are introduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_ecmwf = data_ecmwf.grid\n",
    "cube_aatsr = data_aatsr.grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Peculiarities of time handling when using the `Cube` interface\n",
    "\n",
    "Starting with how time is handled. The time is represented as numerical value relative to a basic date and frequency  unit and in the optimum case, also the specification of a calendar, according to the [NetCDF CF conventions](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.6/build/cf-conventions.html#time-coordinate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECMWF\n",
      "First point:0.0\n",
      "Time unit: day since 2018-01-01 00:00:00.00000000 UTC\n",
      "Calendar: gregorian\n",
      "\n",
      "AATSR\n",
      "First point:0.0\n",
      "Time unit: day since 2008-01-01 00:00:00.00000000 UTC\n",
      "Calendar: julian\n",
      "\n"
     ]
    }
   ],
   "source": [
    "times_ecmwf = cube_ecmwf.coord(\"time\")\n",
    "print(\"ECMWF\\nFirst point:%s\\nTime unit: %s\\nCalendar: %s\\n\" %(times_ecmwf.points[0],\n",
    "                                                               times_ecmwf.units.name, \n",
    "                                                               times_ecmwf.units.calendar))\n",
    "times_aatsr= cube_aatsr.coord(\"time\")\n",
    "print(\"AATSR\\nFirst point:%s\\nTime unit: %s\\nCalendar: %s\\n\" %(times_aatsr.points[0], \n",
    "                                                             times_aatsr.units.name, \n",
    "                                                             times_aatsr.units.calendar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the AATSR data is defined using a Julian calendar. The actual time objects are instances of the `DimCoord` class of the iris package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'iris.coords.DimCoord'> <class 'iris.coords.DimCoord'>\n"
     ]
    }
   ],
   "source": [
    "print(type(times_ecmwf), type(times_aatsr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to convert these numerically represented time stamps into datetime-like objects that, for instance, the `pandas` library understands, we have several options. The first one, which is the most obvious one, is using the provided iris interface which does the conversion for us, that is, using the `cell(index)` method (with the corresponding `index`) of the `DimCoord` class in combination with the `cells()` iterator method. However, as we shall see below, this is not only the slowest solution but it is also prone to errors in case the calendar is not standard (e.g. Julian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time stamp ECMWF 2018-01-01 00:00:00 (data type: <class 'datetime.datetime'>)\n",
      "First time stamp AATSR 2008-01-01 00:00:00 (data type: <class 'netcdftime._netcdftime.DatetimeJulian'>)\n"
     ]
    }
   ],
   "source": [
    "t0_ecmwf = times_ecmwf.cell(0).point\n",
    "t0_aatsr = times_aatsr.cell(0).point\n",
    "print(\"First time stamp ECMWF %s (data type: %s)\" %(t0_ecmwf, type(t0_ecmwf)))\n",
    "print(\"First time stamp AATSR %s (data type: %s)\" %(t0_aatsr, type(t0_aatsr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `cell` method returns different datatypes, dependent on the CF unit convention, that is, a standard Python `datetime.datetime` object, if the calendar is Gregorian, and a `netcdftime._netcdftime.DatetimeJulian` object in case of a Julian calendar. Problem here is, that the former is understood by pandas, while the latter is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError(\"Cannot convert input [2008-01-01 00:00:00] of type <class 'netcdftime._netcdftime.DatetimeJulian'> to Timestamp\",)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "t0_ecmwf_pandas = pandas.Timestamp(t0_ecmwf)\n",
    "try:\n",
    "    t0_aatsr_pandas = pandas.Timestamp(t0_aatsr)\n",
    "except TypeError as e:\n",
    "    print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nontheless, numpy is easier in that sense, since it understands both datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01T00:00:00.000000 2008-01-01T00:00:00.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t0_ecmwf_np = np.datetime64(t0_ecmwf)\n",
    "t0_aatsr_np = np.datetime64(t0_aatsr)\n",
    "print(t0_ecmwf_np, t0_aatsr_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fair enough, but however, in the end we want to ensure to have a conversion method ready that handles any calendar, and that is considerably fast. We just saw, that `datetime64` works for both datetime formats that we get when calling the `cell` method of the `DimCoord` object that holds the time stamps. However, keep in mind, that whenever `cell` is called, it performs a conversion of the numeric value into either `datetime.datetime` or, for non-standard calendars, into a datetime object from the [cftime](https://github.com/Unidata/cftime) package. So, either way, when using the `cell` method we have to iterate over all indices to convert the numerical values into datetime-like objects. The latter may be done using the `cells()` iterator of the `DimCoord` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2018, 1, 1, 0, 0), datetime.datetime(2018, 1, 2, 0, 0)]\n",
      "\n",
      "[netcdftime._netcdftime.DatetimeJulian(2008, 1, 1, 0, 0, 0, 0, -1, 1), netcdftime._netcdftime.DatetimeJulian(2008, 1, 2, 0, 0, 0, 0, -1, 1)]\n"
     ]
    }
   ],
   "source": [
    "times_ecmwf_conv = [t.point for t in times_ecmwf.cells()]\n",
    "times_aatsr_conv = [t.point for t in times_aatsr.cells()]\n",
    "#display first two\n",
    "print(\"%s\\n\\n%s\" %(times_ecmwf_conv[:2],times_aatsr_conv[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worked, but however, is it fast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 ms ± 797 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "[t.point for t in times_ecmwf.cells()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 ms ± 574 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "[t.point for t in times_aatsr.cells()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is: No, it is not fast, and furthermore, the latter datatype will not be accepted by pandas as a valid datetime object. We can, however, convert the datapoints to numpy datetime64 objects during the conversion (if we want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 ms ± 660 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "[np.datetime64(t.point) for t in times_ecmwf.cells()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 ms ± 344 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "[np.datetime64(t.point) for t in times_aatsr.cells()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks okay, since it does not lead to a notable decrease in the performance and ensures, that pandas will understand the datatype. However, about 100ms for conversion of 365 dates is rather slow.\n",
    "\n",
    "##### Other options to convert timestamps \n",
    "\n",
    "Above we saw how we can convert the numerical timestamps into an array of numpy `datetime64` objects (which is what we want in the end). As we shall see below, the conversion can be significantly accelarated if we do not use the iris interface provided by the `cell(index)` method and the `cells()` iterator, but rather directly use the underlying `cftime` library (that iris uses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.68 ms ± 38.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "[np.datetime64(t) for t in times_ecmwf.units.num2date(times_ecmwf.points)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite an improvement. But if we dig a little deeper, we can boost this even more, as we shall see in the following. Basically, what it does is accessing the base date that is encrypted in the unit, i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day since 2018-01-01 00:00:00.00000000 UTC\n"
     ]
    }
   ],
   "source": [
    "print(times_ecmwf.units.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and based on this base date, and the encrypted temporal resolution (here *day*) uses the [pure numpy datetime functionality](https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.datetime.html) to convert the stuff. For this, we have to test if the first sub string (here *day*) is valid according to the CF standard, which we do using some features from the `netCDF4` package and by defining a function, that translates the numerical timestamps into `datetime64` objects based on the information encoded in the units string(e.g. *day since 2018-01-01 00:00:00.00000000 UTC*) and the corresponding calendar (e.g. \"gregorian\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cf_units import Unit\n",
    "from datetime import MINYEAR, datetime\n",
    "from numpy import asarray, datetime64\n",
    "from netCDF4 import (microsec_units, millisec_units, sec_units, min_units,\n",
    "                    hr_units, day_units)\n",
    "from netCDF4._netCDF4 import _dateparse\n",
    "# Start of the gregorian calendar\n",
    "# adapted from here: https://github.com/Unidata/cftime/blob/master/cftime/_cftime.pyx   \n",
    "GREGORIAN_BASE = datetime(1582, 10, 15)\n",
    "\n",
    "def cftime_to_datetime64(timesnum, cfunit, calendar=None):\n",
    "    \"\"\"Convert numerical timestamps with epoch to numpy datetime64\n",
    "    \n",
    "    This method was designed to enhance the performance of datetime conversions\n",
    "    and is based on the corresponding information provided in the cftime \n",
    "    package (`see here <https://github.com/Unidata/cftime/blob/master/cftime/\n",
    "    _cftime.pyx>`__). Particularly, this object does, what the :func:`num2date` \n",
    "    therein does, but faster, in case the time stamps are not defined on a non\n",
    "    standard calendar.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    timesnum : :obj:`list` or :obj:`ndarray`\n",
    "        array containing numerical time stamps (relative to basedate of \n",
    "        ``cfunit``). Can also be a single number.\n",
    "    cfunit : :obj:`str` or :obj:`Unit`\n",
    "        CF unit string (e.g. day since 2018-01-01 00:00:00.00000000 UTC) or\n",
    "        unit\n",
    "    calendar : :obj:`str`, optional\n",
    "        string specifying calendar (only required if ``cfunit`` is of type\n",
    "        ``str``).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        numpy array containing timestamps as datetime64 objects\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        if cfunit is ``str`` and calendar is not provided or invalid, or if \n",
    "        the cfunit string is invalid\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    \n",
    "    >>> cfunit_str = 'day since 2018-01-01 00:00:00.00000000 UTC'\n",
    "    >>> cftime_to_datetime64(10, cfunit_str, \"gregorian\")\n",
    "    array(['2018-01-11T00:00:00.000000'], dtype='datetime64[us]')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        len(timesnum)\n",
    "    except:\n",
    "        timesnum = [timesnum]\n",
    "    if isinstance(cfunit, str):\n",
    "        if calendar is None:\n",
    "            raise ValueError(\"Require specification of calendar for \"\n",
    "                             \"conversion into datetime64 objects\")\n",
    "        cfunit = Unit(cfunit, calendar) #raises Error if calendar is invalid\n",
    "    if not isinstance(cfunit, Unit):\n",
    "        raise ValueError(\"Please provide cfunit either as instance of class \"\n",
    "                         \"cf_units.Unit or as a string\")\n",
    "    cfu_str, calendar = cfunit.name, cfunit.calendar\n",
    "    basedate = _dateparse(cfu_str)\n",
    "    cfu_str = cfunit.name\n",
    "    basedate = _dateparse(cfu_str)  \n",
    "    if ((calendar == 'proleptic_gregorian' and basedate.year >= MINYEAR) or \n",
    "        (calendar in ['gregorian','standard'] and basedate > GREGORIAN_BASE)):\n",
    "        cfu_str = cfunit.name\n",
    "        res = cfu_str.split()[0].lower()\n",
    "        if res in microsec_units:\n",
    "            tstr = \"us\"\n",
    "        elif res in millisec_units:\n",
    "            tstr = \"ms\"\n",
    "        elif res in sec_units:\n",
    "            tstr = \"s\"\n",
    "        elif res in min_units:\n",
    "            tstr = \"m\"\n",
    "        elif res in hr_units:\n",
    "            tstr = \"h\"\n",
    "        elif res in day_units:\n",
    "            tstr = \"D\"\n",
    "        else:\n",
    "            raise ValueError('unsupported time units')\n",
    "        \n",
    "        basedate = datetime64(basedate)\n",
    "        return basedate + asarray(timesnum, dtype=\"timedelta64[%s]\" %tstr)\n",
    "    else:\n",
    "        return asarray([datetime64(t) for t in cfunit.num2date(timesnum)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how this one performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.8 µs ± 291 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cftime_to_datetime64(times_ecmwf.points, times_ecmwf.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How pya does it\n",
    "\n",
    "Due to this significant increase in performance for standard calendars (compared to the methods used in netCDF4), the above method was implemented in the pya package ([see here](aerocom.met.no/pya/api.html#pya.helpers.cftime_to_datetime64))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyaerocom.helpers import cftime_to_datetime64 as pya_tconversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 µs ± 2.34 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pya_tconversion(times_ecmwf.points, times_ecmwf.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the AATSR data, the method is slower, since here, the slower `num2date` method is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.06 ms ± 15.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pya_tconversion(times_aatsr.points, times_aatsr.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is an improvement. Starting with around 100ms when using the iris interface (i.e. iterating over `cells` of the `DimCoord`), for conversion of 365 time stamps, we ended up with the order of 10 microseconds. And at the same time the new method ensures that we have them in a format that also pandas understands. \n",
    "\n",
    "The method is also the standard conversion method in the `GriddedData.time_stamps()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 µs ± 4.59 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_ecmwf.time_stamps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1 ms ± 31.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_aatsr.time_stamps()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
